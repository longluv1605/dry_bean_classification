{"cells":[{"cell_type":"markdown","metadata":{},"source":["# I - Introduction"]},{"cell_type":"markdown","metadata":{},"source":["# II - Prepare required frameworks"]},{"cell_type":"code","execution_count":47,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# import seaborn as sns\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier as RFC\n","from sklearn.neighbors import KNeighborsClassifier as KNC\n","from sklearn.linear_model import LogisticRegression as LR\n","from sklearn.svm import SVC\n","from sklearn.ensemble import GradientBoostingClassifier as GBC\n","import lightgbm as lgbm\n","from sklearn.feature_selection import mutual_info_classif\n","from scipy import stats\n","import joblib"]},{"cell_type":"code","execution_count":48,"metadata":{"trusted":true},"outputs":[],"source":["import warnings\n","\n","# Ẩn tất cả các cảnh báo\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":49,"metadata":{"trusted":true},"outputs":[],"source":["# from sklearnex import patch_sklearn"]},{"cell_type":"code","execution_count":50,"metadata":{"trusted":true},"outputs":[],"source":["# patch_sklearn()"]},{"cell_type":"markdown","metadata":{},"source":["# III - Prepare dataset"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Load dataset"]},{"cell_type":"code","execution_count":51,"metadata":{"trusted":true},"outputs":[],"source":["dataset = pd.read_excel('./Dry_Bean_Dataset.xlsx')"]},{"cell_type":"code","execution_count":52,"metadata":{"trusted":true},"outputs":[],"source":["# dataset.info()"]},{"cell_type":"code","execution_count":53,"metadata":{"trusted":true},"outputs":[],"source":["# dataset.duplicated().sum()"]},{"cell_type":"code","execution_count":54,"metadata":{"trusted":true},"outputs":[],"source":["dataset = dataset.set_index('Bean ID')"]},{"cell_type":"code","execution_count":55,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["Index(['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength',\n","       'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent',\n","       'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2',\n","       'ShapeFactor3', 'ShapeFactor4', 'Class'],\n","      dtype='object')"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["dataset.columns"]},{"cell_type":"code","execution_count":56,"metadata":{"trusted":true},"outputs":[],"source":["features = dataset.columns[:-1]\n","target = dataset.columns[-1]"]},{"cell_type":"code","execution_count":57,"metadata":{"trusted":true},"outputs":[],"source":["# x.describe()"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["x = dataset[features]\n","y = dataset[target]"]},{"cell_type":"code","execution_count":59,"metadata":{"trusted":true},"outputs":[],"source":["scaler = StandardScaler()\n","encoder = LabelEncoder()"]},{"cell_type":"code","execution_count":60,"metadata":{"trusted":true},"outputs":[],"source":["# dataset['Class'] = pd.DataFrame(encoder.fit_transform(dataset['Class']), columns=['Class'])"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"data":{"text/plain":["Class\n","3        3546\n","6        2636\n","5        2027\n","4        1928\n","2        1630\n","0        1322\n","1         522\n","Name: count, dtype: int64"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(encoder.fit_transform(dataset['Class']), columns=['Class']).value_counts()"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["# dataset['Class'].value_counts()"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["def prepare_data(dataset, features, target, scaler, encoder):\n","    x = dataset[features]\n","    y = dataset[target]\n","    y_encoded = encoder.fit_transform(y)\n","    x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=20)\n","    x_train = scaler.fit_transform(x_train)\n","    x_test = scaler.transform(x_test)\n","    return x_train, x_test, y_train, y_test"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = prepare_data(dataset, features, target, scaler, encoder)"]},{"cell_type":"markdown","metadata":{},"source":["# Training models"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["from hyperopt import hp\n","from hyperopt import fmin, tpe, Trials\n","\n","# x_train, x_test, y_train, y_test = prepare_data(dataset, features, target, scaler, encoder)\n","\n","# # Không gian tìm kiếm cho SVM\n","# space = {\n","#     'C': hp.loguniform('C', -4, 2),\n","#     'gamma': hp.loguniform('gamma', -4, -2),\n","#     'kernel': hp.choice('kernel', ['rbf', 'linear'])\n","# }\n","\n","# # Định nghĩa hàm mục tiêu\n","# def objective(params):\n","#     model = SVC(**params)\n","#     score = cross_val_score(model, x_train, y_train, cv=5, n_jobs=-1)\n","#     accuracy = score.mean()\n","#     return -accuracy\n","\n","# # Khởi tạo Trials để lưu trữ kết quả\n","# trials = Trials()\n","\n","# # Thực hiện tìm kiếm hyperparameters\n","# best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)\n","\n","# # Chuyển đổi kết quả tốt nhất\n","# best['kernel'] = ['rbf', 'linear'][best['kernel']]\n","\n","# # In ra kết quả tốt nhất\n","# print(f\"Best parameters: {best}\")\n","\n","# # Đánh giá mô hình trên tập kiểm tra\n","# best_model = SVC(**best)\n","# best_model.fit(x_train, y_train)\n","# test_score = best_model.score(x_test, y_test)\n","# print(f\"Test set score: {test_score}\")\n"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["def hyperopt_search(space, model, x_train, y_train, x_test, y_test, algo=tpe.suggest, max_evals=100, categorical_params={}, trials=None, integer_params=[]):\n","    def objective(params, model=model, x_train=x_train, y_train=y_train, integer_params=integer_params):\n","        for key in integer_params:\n","            if key in params:\n","                params[key] = int(params[key])\n","        model = model(**params)\n","        score = cross_val_score(model, x_train, y_train, cv=5, n_jobs=-1)\n","        accuracy = score.mean()\n","        return -accuracy\n","    \n","    if trials is None:\n","        trials = Trials()\n","    \n","    best = fmin(fn=objective, space=space, algo=algo, max_evals=max_evals, trials=trials)\n","    \n","    for param, idx in categorical_params.items():\n","        best[param] = idx[best[param]]\n","        \n","    for key in integer_params:\n","        if key in best:\n","            best[key] = best[key].astype(int)\n","    \n","    best_model = model(**best)\n","    best_model.fit(x_train, y_train)\n","    test_score = best_model.score(x_test, y_test)\n","    print(f\"Test set score: {test_score}\")\n","    return best_model, best\n"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|██████████| 100/100 [01:30<00:00,  1.11trial/s, best loss: -0.9312094511743737]\n","Test set score: 0.9298567756151304\n"]}],"source":["### SVC\n","\n","space = {\n","    'C': hp.loguniform('C', -2, 4),\n","    'gamma': hp.loguniform('gamma', -4, -2),\n","    'kernel': hp.choice('kernel', ['rbf', 'linear'])\n","}\n","\n","category_params = {\n","    'kernel': ['rbf', 'linear']\n","}\n","\n","best_SVC_model, best_SVC_params = hyperopt_search(space, model=SVC, algo=tpe.suggest, max_evals=100, categorical_params=category_params, \n","                                                  x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters: {'C': 2.182244301323868, 'gamma': 0.1217270894043437, 'kernel': 'rbf'}\n"]}],"source":["# print(f\"Best parameters: {best_SVC_model.get_params()}\")\n","print(f\"Best parameters: {best_SVC_params}\")"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"data":{"text/plain":["['best_SVC_model.pkl']"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["# joblib.dump(best_SVC_model, 'best_SVC_model.pkl')"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["### Random Forest\n","space = {\n","    'n_estimators': hp.quniform('n_estimators', 50, 150, 1),\n","    'max_depth': hp.quniform('max_depth', 5, 20, 1),\n","    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n","    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 10, 1)\n","}\n","\n","category_params = {}\n","\n","int_params = ['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf']\n","\n","# best_RF_model, best_RF_params = hyperopt_search(space, model=RFC, algo=tpe.suggest, max_evals=100, categorical_params=category_params, integer_params=int_params, \n","                                                #   x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'best_RF_model' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[43mbest_RF_model\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_RF_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'best_RF_model' is not defined"]}],"source":["# joblib.dump(best_RF_model, 'best_RF_model.pkl')"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["# print(f\"Best parameters: {best_RF_params}\")"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|██████████| 100/100 [00:27<00:00,  3.61trial/s, best loss: -0.9263418416005379]\n","Test set score: 0.9188395152405435\n"]}],"source":["### KNN\n","space = {\n","    'n_neighbors': hp.quniform('n_neighbors', 1, 20, 1),\n","    'weights': hp.choice('weights', ['uniform', 'distance']),\n","    'p': hp.choice('p', [1, 2])\n","}\n","\n","category_params = {\n","    'weights': ['uniform', 'distance'],\n","    'p': [1, 2]\n","}\n","\n","int_params = ['n_neighbors']\n","\n","best_KNN_model, best_KNN_params = hyperopt_search(space, model=KNC, algo=tpe.suggest, max_evals=100, categorical_params=category_params, integer_params=int_params, \n","                                                  x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters: {'n_neighbors': 16, 'p': 2, 'weights': 'distance'}\n"]}],"source":["print(f\"Best parameters: {best_KNN_params}\")"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"data":{"text/plain":["['best_KNN_model.pkl']"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["# joblib.dump(best_KNN_model, 'best_KNN_model.pkl')"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|██████████| 100/100 [00:38<00:00,  2.57trial/s, best loss: -0.9248720975993703]\n","Test set score: 0.9254498714652957\n"]}],"source":["### Logistic Regression\n","space = {\n","    'C': hp.loguniform('C', -4, 4),\n","    'penalty': hp.choice('penalty', ['l2'])\n","}\n","\n","category_params = {\n","    'penalty': ['l2']\n","}\n","\n","best_LR_model, best_LR_params = hyperopt_search(space, model=LR, algo=tpe.suggest, max_evals=100, categorical_params=category_params, \n","                                                  x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'C': 3.0231657252242194, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"]}],"source":["# print(best_LR_model.get_params())"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters: {'C': 3.0231657252242194, 'penalty': 'l2'}\n"]}],"source":["print(f\"Best parameters: {best_LR_params}\")"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"data":{"text/plain":["['best_LR_model.pkl']"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["# joblib.dump(best_LR_model, 'best_LR_model.pkl')"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|██████████| 100/100 [07:11<00:00,  4.32s/trial, best loss: -0.9291892913348629]\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 4080\n","[LightGBM] [Info] Number of data points in the train set: 10888, number of used features: 16\n","[LightGBM] [Info] Start training from score -2.345560\n","[LightGBM] [Info] Start training from score -3.257546\n","[LightGBM] [Info] Start training from score -2.126837\n","[LightGBM] [Info] Start training from score -1.346678\n","[LightGBM] [Info] Start training from score -1.926446\n","[LightGBM] [Info] Start training from score -1.917658\n","[LightGBM] [Info] Start training from score -1.640973\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","Test set score: 0.9247153874403232\n"]}],"source":["### LightGBM\n","space = {\n","    'n_estimators': hp.quniform('n_estimators', 50, 150, 1),\n","    'max_depth': hp.quniform('max_depth', 5, 20, 1),\n","    'learning_rate': hp.loguniform('learning_rate', -4, 0),\n","    'num_leaves': hp.quniform('num_leaves', 10, 100, 1)\n","}\n","\n","category_params = {}\n","\n","int_params = ['n_estimators', 'max_depth', 'num_leaves']\n","\n","best_LGBM_model, best_LGBM_params = hyperopt_search(space, model=lgbm.LGBMClassifier, algo=tpe.suggest, max_evals=100, categorical_params=category_params, integer_params=int_params, \n","                                                  x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters: {'learning_rate': 0.04094892210733403, 'max_depth': 10, 'n_estimators': 127, 'num_leaves': 11}\n"]}],"source":["print(f\"Best parameters: {best_LGBM_params}\")"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/plain":["['best_LGBM_model.pkl']"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["# joblib.dump(best_LGBM_model, \"best_LGBM_model.pkl\")"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" 15%|█▌        | 15/100 [01:03<06:00,  4.24s/trial, best loss: -0.9209225929483165]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[78], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m category_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     11\u001b[0m int_params \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m best_DT_model, best_DT_params \u001b[38;5;241m=\u001b[39m \u001b[43mhyperopt_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRFC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategory_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteger_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[66], line 14\u001b[0m, in \u001b[0;36mhyperopt_search\u001b[1;34m(space, model, x_train, y_train, x_test, y_test, algo, max_evals, categorical_params, trials, integer_params)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m---> 14\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param, idx \u001b[38;5;129;01min\u001b[39;00m categorical_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     17\u001b[0m     best[param] \u001b[38;5;241m=\u001b[39m idx[best[param]]\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n","Cell \u001b[1;32mIn[66], line 7\u001b[0m, in \u001b[0;36mhyperopt_search.<locals>.objective\u001b[1;34m(params, model, x_train, y_train, integer_params)\u001b[0m\n\u001b[0;32m      5\u001b[0m         params[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(params[key])\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m----> 7\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39maccuracy\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\longt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# ---\n","### Decision Tree\n","space = {\n","    'max_depth': hp.quniform('max_depth', 5, 10, 1),\n","    'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n","    'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 10, 1)\n","}\n","\n","category_params = {}\n","\n","int_params = ['max_depth', 'min_samples_split', 'min_samples_leaf']\n","\n","best_DT_model, best_DT_params = hyperopt_search(space, model=RFC, algo=tpe.suggest, max_evals=100, categorical_params=category_params, integer_params=int_params, \n","                                                  x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"]},{"cell_type":"markdown","metadata":{},"source":["# -------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["----"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["models = {\n","    \"KNeighbors\": KNC(),\n","    \"LogisticRegression\": LR(),\n","    \"RandomForest\": RFC(),\n","    \"SVC\": SVC(),\n","    # \"GradientBoosting\": GBC(),\n","    \"LightGBM\": lgbm.LGBMClassifier(verbose=-1)\n","}\n","\n","def get_scores(models, xtrain, ytrain, xtest, ytest):\n","    for name, model in models.items():\n","        print(f\"-----> {name}\")\n","        model.fit(xtrain, ytrain)\n","        ypred = model.predict(xtest)\n","        model.score(xtest, ytest)\n","        print(\"---> Model score: \", model.score(xtest, ytest))\n","        reports = classification_report(ytest, ypred)\n","        print(\"---> Classification_reports: \\n\", reports)\n","        \n","        # scores = np.mean(cross_val_score(model, xtrain, ytrain, cv=5))\n","        # print(\"---> Cross-validation scores: \\n\", scores)\n","        print(\"============================================\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["get_scores(models, x_train, y_train, x_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["# EDA"]},{"cell_type":"markdown","metadata":{},"source":["# Các thuộc tính\n","Area (A)\tDiện tích:\tDiện tích vùng của hạt đậu và số pixel nằm trong ranh giới của nó.\n","\n","Perimeter (P)\tChu vi:\tChu vi của hạt đậu được định nghĩa là độ dài của đường viền.\n","\n","Major axis length (L)\tĐộ dài trục chính:\tKhoảng cách giữa hai đầu của đường thẳng dài nhất có thể vẽ trên hạt đậu.\n","\n","Minor axis length (l)\tĐộ dài trục phụ:\tĐường thẳng dài nhất có thể vẽ trên hạt đậu theo hướng vuông góc với trục chính.\n","\n","Aspect ratio (K)\tTỷ lệ dài rộng:\tXác định mối quan hệ giữa L và l.\n","\n","Eccentricity (Ec)\tĐộ lệch tâm:\tĐộ lệch tâm của hình elip có cùng các mô men như vùng hạt đậu.\n","\n","Convex area (C)\tDiện tích lồi:\tSố pixel trong đa giác lồi nhỏ nhất có thể chứa diện tích của hạt đậu.\n","\n","Equivalent diameter (Ed)\tĐường kính tương đương:\tĐường kính của một hình tròn có cùng diện tích với diện tích của hạt đậu.\n","\n","Extent (Ex)\tĐộ bao phủ:\tTỷ lệ giữa số pixel trong khung bao và diện tích của hạt đậu.\n","\n","Solidity (S)\tĐộ đặc:\tCòn được gọi là độ lồi. Tỷ lệ giữa số pixel trong vỏ lồi và số pixel tìm thấy trong hạt đậu.\n","\n","Roundness (R)\tĐộ tròn:\tĐược tính toán bằng công thức: (4piA)/(P^2)\n","\n","Compactness (CO)\tĐộ gọn:\tĐo độ tròn của một vật thể: Ed/L\n","\n","ShapeFactor1 (SF1)\tHệ số hình dạng 1:\tTham số hình dạng bổ sung.\n","\n","ShapeFactor2 (SF2)\tHệ số hình dạng 2:\tTham số hình dạng bổ sung.\n","\n","ShapeFactor3 (SF3)\tHệ số hình dạng 3:\tTham số hình dạng bổ sung.\n","\n","ShapeFactor4 (SF4)\tHệ số hình dạng 4:\tTham số hình dạng bổ sung.\n","\n","Class (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz and Sira)\tLớp\tThuộc tính này phân loại hạt đậu thành các loại khác nhau: Seker, Barbunya, Bombay, Cali, Dermosan, Horoz và Sira.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset['Class'].value_counts().plot(kind='bar', xlabel='Types of bean', ylabel='Count')"]},{"cell_type":"markdown","metadata":{},"source":["### Drop outliner"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_heads = x.columns\n","data_heads"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # Biều đồ hist thêm đường trung vị\n","# fig, axes = plt.subplots(4,4, figsize = (24,24))\n","# for i, axe in enumerate(axes.flatten()):\n","#     sns.histplot(data = x[data_heads[i]], ax = axe)\n","#     median = x[data_heads[i]].median()\n","#     axe.set_title(f'{data_heads[i]} (Median = {median:0.1f})')\n","#     axe.axvline(median, color='red', lw=2, alpha=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # Biều đồ Boxplot để xem nhiễu\n","# fig, axes = plt.subplots(4, 4, figsize=(24,24))\n","# for i,axe in enumerate(axes.flatten()):\n","#     sns.boxplot(data = x[data_heads[i]], ax = axe)\n","#     axe.set_title(f'{data_heads[i]}')\n","# plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# fig, axes = plt.subplots(8, 2, figsize=(24,48))\n","# for feature, ax in zip(x.columns, axes.flatten()):\n","#     sns.violinplot(data = dataset, x = 'Class', y = feature, ax = ax, inner=\"quartile\" )\n","#     ax.set(xlabel = None)\n","#     ax.set_title(f'Phân bố {feature} từng loại')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def drop_outliers(dataset, features):\n","    # Tính toán Z-score cho mỗi điểm dữ liệu\n","    z_scores = stats.zscore(dataset[features])\n","\n","    # Xác định ngưỡng cho Z-score\n","    threshold = 3\n","\n","    # Loại bỏ các outlier\n","    dataset_cleaned = dataset.loc[(z_scores < threshold).all(axis=1)]\n","\n","    # In ra số lượng outlier đã loại bỏ\n","    outliers_removed = dataset.shape[0] - dataset_cleaned.shape[0]\n","    print(\"Số lượng outlier đã loại bỏ:\", outliers_removed)\n","    return dataset_cleaned"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_cleaned = drop_outliers(dataset, features)\n","x_train, x_test, y_train, y_test = prepare_data(dataset_cleaned, features, target, scaler, encoder)\n","# get_scores(models, x_train, y_train, x_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Drop large corr"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # correlation matrix\n","# plt.figure(figsize=(20,20))\n","# sns.heatmap(x.corr(),annot = True, cmap = 'viridis_r', fmt = '.2f');"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def drop_corr(dataset, features):\n","    # Đọc dữ liệu từ file CSV hoặc tạo ma trận tương quan từ dữ liệu hiện có\n","    corr_matrix = dataset[features].corr().abs()\n","\n","    # Chọn ngưỡng tương quan\n","    threshold = 0.8\n","\n","    # Tạo một bản sao của ma trận tương quan\n","    mask = corr_matrix.copy()\n","\n","    # Thiết lập giá trị True cho các ô phía trên đường chéo chính\n","    # mask[np.triu_indices_from(mask.values)] = 0\n","\n","    for i in range(len(mask.columns)):\n","        for j in range(i + 1):\n","            mask.iloc[i,j] = 0\n","\n","    # print(mask)\n","    # Loại bỏ các biến dựa trên ngưỡng tương quan\n","    drop_cols = [column for column in mask.columns if any(mask[column] > threshold)]\n","\n","    # Loại bỏ các cột từ DataFrame\n","    dataset_filtered = dataset.drop(drop_cols, axis=1)\n","    return dataset_filtered"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_filtered = drop_corr(dataset_cleaned, features)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = prepare_data(dataset_filtered, dataset_filtered.columns[:-1], dataset_filtered.columns[-1], scaler, encoder)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get_scores(models, x_train, y_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Strongly_corr_features = dataset[[\"Area\",\"Perimeter\",\"AspectRation\",\"Eccentricity\",\"roundness\",\"Compactness\",\"Class\"]]\n","# Strongly_corr_features.head()\n","# sns.set_theme(style=\"whitegrid\")\n","# sns.pairplot(Strongly_corr_features, hue=\"Class\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mi_scores = mutual_info_classif(x, y, random_state = 31)\n","mi_scores_df = pd.DataFrame({'Feature': x.columns, 'MI Score': mi_scores})\n","mi_scores_df = mi_scores_df.sort_values(by='MI Score', ascending=False).reset_index(drop=True)\n","\n","# plt.figure(figsize=(20,10))\n","# sns.barplot(x='MI Score', y='Feature', data=mi_scores_df) \n","# plt.xlabel('Mutual Information Score')\n","# # plt.ylabel('Feature')\n","# plt.title('Mutual Information Scores for Each Feature')\n","# # plt.gca().invert_yaxis() # sắp xếp lại theo giảm dần\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Drop large corr and outliner"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = drop_corr(dataset_cleaned, features)\n","x_train, x_test, y_train, y_test = prepare_data(data, data.columns[:-1], data.columns[-1], scaler, encoder)\n","# get_scores(models, x_train, y_train, x_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["# * Data augmentation"]},{"cell_type":"markdown","metadata":{},"source":["## ** SMOTE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["! pip install imbalanced-learn\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from imblearn.over_sampling import SMOTE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = prepare_data(dataset, dataset.columns[:-1], dataset.columns[-1], scaler, encoder)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["smote = SMOTE(random_state=42)\n","x_train_resampled, y_train_resampled = smote.fit_resample(x_train, y_train)\n","\n","# for i in range(4):\n","#     x_train_resampled, y_train_resampled = smote.fit_resample(x_train_resampled, y_train_resampled)\n","print(x_train_resampled.shape)    \n","print(y_train_resampled.shape)\n","\n","# get_scores(models, x_train_resampled, y_train_resampled, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.DataFrame(y_train).value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["## ** Feature perturbation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = dataset[features]\n","y = dataset[target]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["traindf = pd.DataFrame(x_train, columns=features)\n","traindf['Class'] = y_train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["countdf = traindf['Class'].value_counts()\n","for i in countdf.index:\n","    countdf[i] = 3500 / countdf[i]\n","countdf"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hàm để thêm nhiễu Gaussian\n","\n","df1 = traindf.loc[traindf['Class'] == 'DERMASON']\n","df2 = traindf.loc[traindf['Class'] == 'SIRA']\n","df3 = traindf.loc[traindf['Class'] == 'SEKER']\n","df4 = traindf.loc[traindf['Class'] == 'HOROZ']\n","df5 = traindf.loc[traindf['Class'] == 'CALI']\n","df6 = traindf.loc[traindf['Class'] == 'BARBUNYA']\n","df7 = traindf.loc[traindf['Class'] == 'BOMBAY']\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Hàm để thêm nhiễu Gaussian\n","def add_gaussian_noise(series, mean=0, std_dev=0.1):\n","    noise = np.random.normal(mean, std_dev, series.shape)\n","    return series + noise\n","\n","def add_noise(df):\n","    for column in df.columns:\n","        if column != 'Class':\n","            df[column] = add_gaussian_noise(df[column])\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in countdf.index:\n","    if i == 'DERMASON':\n","        cp = df1.copy()\n","        for j in range(round(countdf[i]) - 2):\n","            df1 = pd.concat([df1, add_noise(cp)])\n","    elif i == 'SIRA':\n","        cp = df2.copy()\n","        for j in range(round(countdf[i]) - 2):\n","            df2 = pd.concat([df2, add_noise(cp)])\n","    elif i == 'SEKER':\n","        cp = df3.copy()\n","        for j in range(round(countdf[i]) - 2):\n","            df3 = pd.concat([df3, add_noise(cp)])\n","    elif i == 'HOROZ':\n","        cp = df4.copy()\n","        for j in range(round(countdf[i]) - 2):\n","            df4 = pd.concat([df4, add_noise(cp)])\n","    elif i == 'CALI':\n","        cp = df5.copy()\n","        for j in range(round(countdf[i]) - 2):\n","            df5 = pd.concat([df5, add_noise(cp)])\n","    elif i == 'BARBUNYA':\n","        cp = df6.copy()\n","        for j in range(round(countdf[i]) - 2):\n","            df6 = pd.concat([df6, add_noise(cp)])\n","    elif i == 'BOMBAY':\n","        cp = df7.copy()\n","        for j in range(round(countdf[i]) - 2):\n","            df7 = pd.concat([df7, add_noise(cp)])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.concat([df1, df2, df3, df4, df5, df6, df7])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['Class'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fp_data = pd.concat([traindf, df], axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fp_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fp_data['Class'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# fp_x_train, fp_x_test, fp_y_train, fp_y_test = prepare_data(fp_data, fp_data.columns[:-1], fp_data.columns[-1], scaler, encoder)\n","x_fp_train = fp_data[features]\n","y_fp_train = fp_data[target]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["target"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get_scores(models, x_fp_train, y_fp_train, x_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["## ** Synthetic data generation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.mixture import GaussianMixture"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Chuyển đổi các đặc trưng phân loại sang số (encoding)\n","df_encoded = pd.get_dummies(dataset, columns=['Class'])\n","\n","# Chuẩn bị dữ liệu cho mô hình GMM\n","X = df_encoded.values\n","\n","# Khởi tạo và huấn luyện mô hình Gaussian Mixture Model\n","gmm = GaussianMixture(n_components=3, random_state=42)\n","gmm.fit(X)\n","\n","# Sinh dữ liệu mới từ mô hình GMM\n","num_samples = 10000  # Số lượng mẫu mới cần tạo\n","X_synthetic = gmm.sample(num_samples)[0]\n","\n","# Chuyển đổi dữ liệu sinh ngược lại thành DataFrame\n","df_synthetic = pd.DataFrame(X_synthetic, columns=df_encoded.columns)\n","\n","# Đảo ngược quá trình encoding để có các đặc trưng phân loại\n","for class_label in dataset['Class'].unique():\n","    df_synthetic[class_label] = (dataset['Class'] == class_label).astype(int)\n","\n","# Thêm nhãn giả lập (hoặc có thể sử dụng một mô hình để dự đoán nhãn)\n","df_synthetic['Label'] = np.random.choice(dataset['Class'].unique(), size=num_samples)\n","\n","# In ra dữ liệu mới\n","print(\"Dữ liệu sau khi sinh từ GMM:\")\n","df_synthetic.head()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5049615,"sourceId":8468982,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
